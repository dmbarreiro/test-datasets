{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Bach Chorales Harmony"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset contains pitch class information of 60 Bach chorales. The dataset divides each chorale as a \"harmonic time series\" with each row containing pitch information in the twelve-tone equal temperament tuning system with 12 columns containing binary information (present or not) for each of the 12 pitch classes. It also contains one column with information about the bass pitch and one column with meter information which is a number from 1 to 5 that indicates how accented the time event is (being 5 more accecente and 1 less accented). Finally the last column contains the chord label resonating during the given time event.\n",
    "Dataset contains 5665 time events and was obtained from [here](https://archive.ics.uci.edu/ml/datasets/Bach+Choral+Harmony)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pathmagic  # noqa\n",
    "import dataset_manipulation as daux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start loading dataset (CSV format) in pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_dataset_path = r'jsbach_chorals_harmony.data'\n",
    "dataset = pd.read_csv(raw_dataset_path, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset in training (80%) and testing (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, test = split_dataframe(dataset, split_probability=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract published performance (8th column of the dataset) for training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_training = training[8].copy()\n",
    "y_test = test[8].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary columns so we are left only with the desired features. The removed columns contain: \n",
    "- Vendor name - column 0 \n",
    "- Model name - column 1\n",
    "- Published relative performance - column 8\n",
    "- Estimated relative performance - column 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_array = np.array([0,1,8,9])  # Select columns to drop\n",
    "X_training = training.drop(drop_array, axis=1)  # axis=1 for columns, axis=0 for rows\n",
    "X_test = test.drop(drop_array, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed now with data preprocessing for ridge regression which consists of:\n",
    "1. Substraction the mean off of y  \n",
    "\n",
    "\\begin{equation*}\n",
    "y \\leftarrow y - \\frac{1}{n} \\sum_{i=1}^n y_i\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training = y_training - np.mean(y_training)\n",
    "y_test = y_test - np.mean(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Standardize dimensions of $x_i$\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{ij} \\leftarrow \\frac{(x_{ij} - \\bar{x}_{.j})}{\\hat{\\sigma}_j}, \\quad \\hat{\\sigma}_j = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_{ij} - \\bar{x}_{.j})^2}\n",
    "\\end{equation*} \n",
    "\n",
    "This is, substract the empirical mean and divide by the empirical standard deviation for each dimention for every example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training data\n",
    "X_training_column_mean = np.mean(X_training, axis=0)\n",
    "X_training_column_mean = np.tile(X_training_column_mean, (X_training.shape[0], 1))\n",
    "std_training_column = np.sqrt(np.mean(np.square(X_training - X_training_column_mean), axis=0))\n",
    "std_training_column = np.tile(std_training_column, (X_training.shape[0], 1))\n",
    "X_training = (X_training - X_training_column_mean) / std_training_column\n",
    "\n",
    "\n",
    "# For test data\n",
    "X_test_column_mean = np.mean(X_test, axis=0)\n",
    "X_test_column_mean = np.tile(X_test_column_mean, (X_test.shape[0], 1))\n",
    "std_test_column = np.sqrt(np.mean(np.square(X_test - X_test_column_mean), axis=0))\n",
    "std_test_column = np.tile(std_test_column, (X_test.shape[0], 1))\n",
    "X_test = (X_test - X_test_column_mean) / std_test_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to standardization of the data there is no need for inserting offset column of ones in the beginning of the data but here is the example code (commented out) anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_training.insert(0, 0, 1)  # Insert a column of ones for the offset\n",
    "#X_test.insert(0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all the processed data in four CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_training.to_csv(r'y_training', index=False, header=None)\n",
    "y_test.to_csv(r'y_test', index=False, header=None)\n",
    "X_training.to_csv(r'X_training', index=False, header=None)\n",
    "X_test.to_csv(r'X_test', index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
