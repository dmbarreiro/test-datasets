{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Bach Chorales Harmony"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset contains pitch class information of 60 Bach chorales. The dataset divides each chorale as a \"harmonic time series\" with each row containing pitch information in the twelve-tone equal temperament tuning system with 12 columns containing binary information (present or not) for each of the 12 pitch classes. It also contains one column with information about the bass pitch and one column with meter information which is a number from 1 to 5 that indicates how accented the time event is (being 5 more accecente and 1 less accented). Finally the last column contains the chord label resonating during the given time event.\n",
    "Dataset contains 5665 time events and was obtained from [here](https://archive.ics.uci.edu/ml/datasets/Bach+Choral+Harmony)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pathmagic  # noqa\n",
    "import dataset_manipulation as daux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start loading dataset (CSV format) in pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_dataset_path = r'jsbach_chorals_harmony.data'\n",
    "dataset = pd.read_csv(raw_dataset_path, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset in training (80%) and testing (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, test = daux.split_dataframe(dataset, split_probability=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract chord label(16th column of the dataset) for training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_training = training[16].copy()\n",
    "y_test = test[16].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unwanted information so we are left only with the desired features. The removed columns contain: \n",
    "- Choral ID: Corresponding to the file names from [Bach Central](http://www.bachcentral.com) - column 0\n",
    "- Chord label: Chord resonating during the given event - column 16\n",
    "\n",
    "I was inclined to remove columns 15 (chord bass note) and 15 (accent meter) but finally I left them since it was the intention of the authors to carry out the classification using these features and the information they provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_array = np.array([0,16])  # Select columns to drop\n",
    "X_training = training.drop(drop_array, axis=1)  # axis=1 for columns, axis=0 for rows\n",
    "X_test = test.drop(drop_array, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unnecessary columns is not so important for Naive Bayes since it is quite robust to irrelevant attributes. We could check that leaving irrelevant columns in the dataset and comparing algorithm results with and without them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No offset column of ones inserted in the beginning of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_training.insert(0, 0, 1)  # Insert a column of ones for the offset\n",
    "#X_test.insert(0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all the processed data in four CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_training.to_csv(r'y_training', index=False, header=None)\n",
    "y_test.to_csv(r'y_test', index=False, header=None)\n",
    "X_training.to_csv(r'X_training', index=False, header=None)\n",
    "X_test.to_csv(r'X_test', index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
