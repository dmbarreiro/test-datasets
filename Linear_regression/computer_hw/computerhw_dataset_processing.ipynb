{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression: Computer hardware dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset contains hardware attributes, published performance and estimated performance using linear regression. It was obtained from [here](https://archive.ics.uci.edu/ml/datasets/Computer+Hardware)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pathmagic  # noqa\n",
    "import dataset_manipulation as daux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start loading dataset (CSV format) in pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_dataset_path = r'original.data'\n",
    "dataset = pd.read_csv(raw_dataset_path, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset in training (80%) and testing (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, test = daux.split_dataframe(dataset, split_probability=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract published performance (8th column of the dataset) for training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_training = training[8].copy()\n",
    "y_test = test[8].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary columns so we are left only with the desired features. The removed columns contain: \n",
    "- Vendor name - column 0 \n",
    "- Model name - column 1\n",
    "- Published relative performance - column 8\n",
    "- Estimated relative performance - column 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_array = np.array([0,1,8,9])  # Select columns to drop\n",
    "X_training = training.drop(drop_array, axis=1)  # axis=1 for columns, axis=0 for rows\n",
    "X_test = test.drop(drop_array, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed now with data preprocessing for ridge regression which consists of:\n",
    "1. Substraction the mean off of y  \n",
    "\n",
    "\\begin{equation*}\n",
    "y \\leftarrow y - \\frac{1}{n} \\sum_{i=1}^n y_i\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training = y_training - np.mean(y_training)\n",
    "y_test = y_test - np.mean(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Standardize dimensions of $x_i$\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{ij} \\leftarrow \\frac{(x_{ij} - \\bar{x}_{.j})}{\\hat{\\sigma}_j}, \\quad \\hat{\\sigma}_j = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_{ij} - \\bar{x}_{.j})^2}\n",
    "\\end{equation*} \n",
    "\n",
    "This is, substract the empirical mean and divide by the empirical standard deviation for each dimention for every example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training data\n",
    "X_training_column_mean = np.mean(X_training, axis=0)\n",
    "X_training_column_mean = np.tile(X_training_column_mean, (X_training.shape[0], 1))\n",
    "std_training_column = np.sqrt(np.mean(np.square(X_training - X_training_column_mean), axis=0))\n",
    "std_training_column = np.tile(std_training_column, (X_training.shape[0], 1))\n",
    "X_training = (X_training - X_training_column_mean) / std_training_column\n",
    "\n",
    "\n",
    "# For test data\n",
    "X_test_column_mean = np.mean(X_test, axis=0)\n",
    "X_test_column_mean = np.tile(X_test_column_mean, (X_test.shape[0], 1))\n",
    "std_test_column = np.sqrt(np.mean(np.square(X_test - X_test_column_mean), axis=0))\n",
    "std_test_column = np.tile(std_test_column, (X_test.shape[0], 1))\n",
    "X_test = (X_test - X_test_column_mean) / std_test_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to standardization of the data there is no need for inserting offset column of ones in the beginning of the data but here is the example code (commented out) anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_training.insert(0, 0, 1)  # Insert a column of ones for the offset\n",
    "#X_test.insert(0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all the processed data in four CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_training.to_csv(r'y_training', index=False, header=None)\n",
    "y_test.to_csv(r'y_test', index=False, header=None)\n",
    "X_training.to_csv(r'X_training', index=False, header=None)\n",
    "X_test.to_csv(r'X_test', index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
